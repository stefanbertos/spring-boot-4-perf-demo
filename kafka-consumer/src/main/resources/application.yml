spring:
  application:
    name: kafka-consumer
  config:
    import: optional:configserver:${CONFIG_SERVER_URL:http://localhost:8888}
  docker:
    compose:
      file: ../infrastructure/docker/compose.yaml
  kafka:
    bootstrap-servers: localhost:9092
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: com.example.avro.serialization.AvroSerializer
      acks: 1
      compression-type: lz4
      properties:
        linger.ms: 5
        batch.size: 65536
    consumer:
      group-id: kafka-consumer-group
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: com.example.avro.serialization.AvroDeserializer

app:
  kafka:
    topic:
      request: mq-requests
      response: mq-responses
    consumer:
      concurrency: 20

management:
  endpoints:
    web:
      exposure:
        include: health,info,prometheus
  endpoint:
    health:
      probes:
        enabled: true
      show-details: always
  health:
    livenessstate:
      enabled: true
    readinessstate:
      enabled: true
  prometheus:
    metrics:
      export:
        enabled: true

logging:
  level:
    root: INFO
    com.example: INFO
    org.springframework: INFO
    org.apache.kafka: WARN

{
  "annotations": {
    "list": []
  },
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 1,
  "id": null,
  "links": [],
  "panels": [
    {
      "title": "HTTP Request Rate",
      "type": "timeseries",
      "gridPos": { "h": 8, "w": 12, "x": 0, "y": 0 },
      "datasource": { "type": "prometheus", "uid": "prometheus" },
      "targets": [
        {
          "expr": "rate(http_server_requests_seconds_count{job=\"perf-tester\"}[$__rate_interval])",
          "legendFormat": "{{method}} {{uri}} - {{status}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "reqps"
        },
        "overrides": []
      }
    },
    {
      "title": "HTTP Response Time (avg)",
      "type": "timeseries",
      "gridPos": { "h": 8, "w": 12, "x": 12, "y": 0 },
      "datasource": { "type": "prometheus", "uid": "prometheus" },
      "targets": [
        {
          "expr": "rate(http_server_requests_seconds_sum{job=\"perf-tester\"}[$__rate_interval]) / rate(http_server_requests_seconds_count{job=\"perf-tester\"}[$__rate_interval])",
          "legendFormat": "avg - {{method}} {{uri}}"
        },
        {
          "expr": "histogram_quantile(0.95, rate(http_server_requests_seconds_bucket{job=\"perf-tester\"}[$__rate_interval]))",
          "legendFormat": "p95"
        },
        {
          "expr": "histogram_quantile(0.99, rate(http_server_requests_seconds_bucket{job=\"perf-tester\"}[$__rate_interval]))",
          "legendFormat": "p99"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "s"
        },
        "overrides": []
      }
    },
    {
      "title": "MQ E2E TPS",
      "type": "timeseries",
      "gridPos": { "h": 8, "w": 12, "x": 0, "y": 8 },
      "datasource": { "type": "prometheus", "uid": "prometheus" },
      "targets": [
        {
          "expr": "rate(mq_e2e_latency_seconds_count{job=\"perf-tester\"}[$__rate_interval])",
          "legendFormat": "E2E TPS"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "ops"
        },
        "overrides": []
      }
    },
    {
      "title": "MQ E2E Latency Percentiles",
      "type": "timeseries",
      "gridPos": { "h": 8, "w": 12, "x": 12, "y": 8 },
      "datasource": { "type": "prometheus", "uid": "prometheus" },
      "targets": [
        {
          "expr": "histogram_quantile(0.50, sum(rate(mq_e2e_latency_seconds_bucket{job=\"perf-tester\"}[$__rate_interval])) by (le))",
          "legendFormat": "p50"
        },
        {
          "expr": "histogram_quantile(0.95, sum(rate(mq_e2e_latency_seconds_bucket{job=\"perf-tester\"}[$__rate_interval])) by (le))",
          "legendFormat": "p95"
        },
        {
          "expr": "histogram_quantile(0.99, sum(rate(mq_e2e_latency_seconds_bucket{job=\"perf-tester\"}[$__rate_interval])) by (le))",
          "legendFormat": "p99"
        },
        {
          "expr": "rate(mq_e2e_latency_seconds_sum{job=\"perf-tester\"}[$__rate_interval]) / rate(mq_e2e_latency_seconds_count{job=\"perf-tester\"}[$__rate_interval])",
          "legendFormat": "avg"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "s"
        },
        "overrides": []
      }
    },
    {
      "title": "MQ Listener TPS (MQ → Kafka)",
      "type": "timeseries",
      "gridPos": { "h": 8, "w": 8, "x": 0, "y": 16 },
      "datasource": { "type": "prometheus", "uid": "prometheus" },
      "targets": [
        {
          "expr": "sum(rate(mq_listener_process_time_seconds_count{job=\"ibm-mq-consumer\"}[$__rate_interval]))",
          "legendFormat": "TPS"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "ops"
        },
        "overrides": []
      }
    },
    {
      "title": "MQ Listener Latency (MQ → Kafka)",
      "type": "timeseries",
      "gridPos": { "h": 8, "w": 8, "x": 8, "y": 16 },
      "datasource": { "type": "prometheus", "uid": "prometheus" },
      "targets": [
        {
          "expr": "histogram_quantile(0.95, sum(rate(mq_listener_process_time_seconds_bucket{job=\"ibm-mq-consumer\"}[$__rate_interval])) by (le))",
          "legendFormat": "p95"
        },
        {
          "expr": "histogram_quantile(0.99, sum(rate(mq_listener_process_time_seconds_bucket{job=\"ibm-mq-consumer\"}[$__rate_interval])) by (le))",
          "legendFormat": "p99"
        },
        {
          "expr": "sum(rate(mq_listener_process_time_seconds_sum{job=\"ibm-mq-consumer\"}[$__rate_interval])) / sum(rate(mq_listener_process_time_seconds_count{job=\"ibm-mq-consumer\"}[$__rate_interval]))",
          "legendFormat": "avg"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "s"
        },
        "overrides": []
      }
    },
    {
      "title": "MQ Listener Messages",
      "type": "timeseries",
      "gridPos": { "h": 8, "w": 8, "x": 16, "y": 16 },
      "datasource": { "type": "prometheus", "uid": "prometheus" },
      "targets": [
        {
          "expr": "sum(rate(mq_listener_messages_received_total{job=\"ibm-mq-consumer\"}[$__rate_interval]))",
          "legendFormat": "received/s"
        },
        {
          "expr": "sum(rate(mq_listener_messages_forwarded_total{job=\"ibm-mq-consumer\"}[$__rate_interval]))",
          "legendFormat": "forwarded/s"
        },
        {
          "expr": "sum(rate(mq_listener_messages_dropped_total{job=\"ibm-mq-consumer\"}[$__rate_interval]))",
          "legendFormat": "dropped/s"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "ops"
        },
        "overrides": []
      }
    },
    {
      "title": "Kafka Request TPS (Processing)",
      "type": "timeseries",
      "gridPos": { "h": 8, "w": 8, "x": 0, "y": 24 },
      "datasource": { "type": "prometheus", "uid": "prometheus" },
      "targets": [
        {
          "expr": "sum(rate(kafka_request_process_time_seconds_count{job=\"kafka-consumer\"}[$__rate_interval]))",
          "legendFormat": "TPS"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "ops"
        },
        "overrides": []
      }
    },
    {
      "title": "Kafka Request Latency (Processing)",
      "type": "timeseries",
      "gridPos": { "h": 8, "w": 8, "x": 8, "y": 24 },
      "datasource": { "type": "prometheus", "uid": "prometheus" },
      "targets": [
        {
          "expr": "histogram_quantile(0.95, sum(rate(kafka_request_process_time_seconds_bucket{job=\"kafka-consumer\"}[$__rate_interval])) by (le))",
          "legendFormat": "p95"
        },
        {
          "expr": "histogram_quantile(0.99, sum(rate(kafka_request_process_time_seconds_bucket{job=\"kafka-consumer\"}[$__rate_interval])) by (le))",
          "legendFormat": "p99"
        },
        {
          "expr": "sum(rate(kafka_request_process_time_seconds_sum{job=\"kafka-consumer\"}[$__rate_interval])) / sum(rate(kafka_request_process_time_seconds_count{job=\"kafka-consumer\"}[$__rate_interval]))",
          "legendFormat": "avg"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "s"
        },
        "overrides": []
      }
    },
    {
      "title": "Kafka Request Messages",
      "type": "timeseries",
      "gridPos": { "h": 8, "w": 8, "x": 16, "y": 24 },
      "datasource": { "type": "prometheus", "uid": "prometheus" },
      "targets": [
        {
          "expr": "sum(rate(kafka_request_messages_received_total{job=\"kafka-consumer\"}[$__rate_interval]))",
          "legendFormat": "received/s"
        },
        {
          "expr": "sum(rate(kafka_request_messages_processed_total{job=\"kafka-consumer\"}[$__rate_interval]))",
          "legendFormat": "processed/s"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "ops"
        },
        "overrides": []
      }
    },
    {
      "title": "Kafka Response TPS (Kafka → MQ)",
      "type": "timeseries",
      "gridPos": { "h": 8, "w": 8, "x": 0, "y": 32 },
      "datasource": { "type": "prometheus", "uid": "prometheus" },
      "targets": [
        {
          "expr": "sum(rate(kafka_response_process_time_seconds_count{job=\"ibm-mq-consumer\"}[$__rate_interval]))",
          "legendFormat": "TPS"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "ops"
        },
        "overrides": []
      }
    },
    {
      "title": "Kafka Response Latency (Kafka → MQ)",
      "type": "timeseries",
      "gridPos": { "h": 8, "w": 8, "x": 8, "y": 32 },
      "datasource": { "type": "prometheus", "uid": "prometheus" },
      "targets": [
        {
          "expr": "histogram_quantile(0.95, sum(rate(kafka_response_process_time_seconds_bucket{job=\"ibm-mq-consumer\"}[$__rate_interval])) by (le))",
          "legendFormat": "p95"
        },
        {
          "expr": "histogram_quantile(0.99, sum(rate(kafka_response_process_time_seconds_bucket{job=\"ibm-mq-consumer\"}[$__rate_interval])) by (le))",
          "legendFormat": "p99"
        },
        {
          "expr": "sum(rate(kafka_response_process_time_seconds_sum{job=\"ibm-mq-consumer\"}[$__rate_interval])) / sum(rate(kafka_response_process_time_seconds_count{job=\"ibm-mq-consumer\"}[$__rate_interval]))",
          "legendFormat": "avg"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "s"
        },
        "overrides": []
      }
    },
    {
      "title": "Kafka Response Messages",
      "type": "timeseries",
      "gridPos": { "h": 8, "w": 8, "x": 16, "y": 32 },
      "datasource": { "type": "prometheus", "uid": "prometheus" },
      "targets": [
        {
          "expr": "sum(rate(kafka_response_messages_received_total{job=\"ibm-mq-consumer\"}[$__rate_interval]))",
          "legendFormat": "received/s"
        },
        {
          "expr": "sum(rate(kafka_response_messages_sent_total{job=\"ibm-mq-consumer\"}[$__rate_interval]))",
          "legendFormat": "sent to MQ/s"
        },
        {
          "expr": "sum(rate(kafka_response_messages_dropped_total{job=\"ibm-mq-consumer\"}[$__rate_interval]))",
          "legendFormat": "dropped/s"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "ops"
        },
        "overrides": []
      }
    },
    {
      "title": "JVM Heap Memory",
      "type": "timeseries",
      "gridPos": { "h": 8, "w": 12, "x": 0, "y": 40 },
      "datasource": { "type": "prometheus", "uid": "prometheus" },
      "targets": [
        {
          "expr": "sum(jvm_memory_used_bytes{job=\"perf-tester\", area=\"heap\"})",
          "legendFormat": "perf-tester"
        },
        {
          "expr": "sum(jvm_memory_used_bytes{job=\"ibm-mq-consumer\", area=\"heap\"})",
          "legendFormat": "ibm-mq-consumer"
        },
        {
          "expr": "sum(jvm_memory_used_bytes{job=\"kafka-consumer\", area=\"heap\"})",
          "legendFormat": "kafka-consumer"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "bytes"
        },
        "overrides": []
      }
    },
    {
      "title": "CPU Usage",
      "type": "timeseries",
      "gridPos": { "h": 8, "w": 12, "x": 12, "y": 40 },
      "datasource": { "type": "prometheus", "uid": "prometheus" },
      "targets": [
        {
          "expr": "process_cpu_usage{job=\"perf-tester\"}",
          "legendFormat": "perf-tester"
        },
        {
          "expr": "avg(process_cpu_usage{job=\"ibm-mq-consumer\"})",
          "legendFormat": "ibm-mq-consumer (avg)"
        },
        {
          "expr": "avg(process_cpu_usage{job=\"kafka-consumer\"})",
          "legendFormat": "kafka-consumer (avg)"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "percentunit",
          "max": 1
        },
        "overrides": []
      }
    },
    {
      "title": "GC Overhead",
      "type": "timeseries",
      "gridPos": { "h": 8, "w": 12, "x": 0, "y": 48 },
      "datasource": { "type": "prometheus", "uid": "prometheus" },
      "targets": [
        {
          "expr": "jvm_gc_overhead{job=\"perf-tester\"}",
          "legendFormat": "perf-tester"
        },
        {
          "expr": "avg(jvm_gc_overhead{job=\"ibm-mq-consumer\"})",
          "legendFormat": "ibm-mq-consumer (avg)"
        },
        {
          "expr": "avg(jvm_gc_overhead{job=\"kafka-consumer\"})",
          "legendFormat": "kafka-consumer (avg)"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "percentunit",
          "max": 1
        },
        "overrides": []
      }
    },
    {
      "title": "JVM Threads",
      "type": "timeseries",
      "gridPos": { "h": 8, "w": 12, "x": 12, "y": 48 },
      "datasource": { "type": "prometheus", "uid": "prometheus" },
      "targets": [
        {
          "expr": "jvm_threads_live_threads{job=\"perf-tester\"}",
          "legendFormat": "perf-tester"
        },
        {
          "expr": "sum(jvm_threads_live_threads{job=\"ibm-mq-consumer\"})",
          "legendFormat": "ibm-mq-consumer (total)"
        },
        {
          "expr": "sum(jvm_threads_live_threads{job=\"kafka-consumer\"})",
          "legendFormat": "kafka-consumer (total)"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "short"
        },
        "overrides": []
      }
    },
    {
      "title": "Service Health Status",
      "type": "stat",
      "gridPos": { "h": 6, "w": 12, "x": 0, "y": 56 },
      "datasource": { "type": "prometheus", "uid": "prometheus" },
      "targets": [
        {
          "expr": "health_mq_status{job=\"perf-tester\"}",
          "legendFormat": "IBM MQ"
        },
        {
          "expr": "health_kafka_status{job=\"perf-tester\"}",
          "legendFormat": "Kafka"
        },
        {
          "expr": "health_oracle_status{job=\"perf-tester\"}",
          "legendFormat": "Oracle"
        },
        {
          "expr": "health_redis_status{job=\"perf-tester\"}",
          "legendFormat": "Redis"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "mappings": [
            {
              "type": "value",
              "options": {
                "0": { "text": "DOWN", "color": "red" },
                "1": { "text": "UP", "color": "green" }
              }
            }
          ],
          "unit": "short"
        },
        "overrides": []
      }
    },
    {
      "title": "Health Check Ping Duration",
      "type": "timeseries",
      "gridPos": { "h": 6, "w": 12, "x": 12, "y": 56 },
      "datasource": { "type": "prometheus", "uid": "prometheus" },
      "targets": [
        {
          "expr": "rate(health_ping_duration_seconds_sum{job=\"perf-tester\"}[$__rate_interval]) / rate(health_ping_duration_seconds_count{job=\"perf-tester\"}[$__rate_interval])",
          "legendFormat": "{{service}} avg"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "s"
        },
        "overrides": []
      }
    }
  ],
  "refresh": "30s",
  "schemaVersion": 39,
  "templating": {
    "list": []
  },
  "time": {
    "from": "now-15m",
    "to": "now"
  },
  "title": "Spring Boot - perf-demo",
  "uid": "spring-boot-perf-demo",
  "version": 1
}

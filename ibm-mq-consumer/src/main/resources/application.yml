spring:
  application:
    name: ibm-mq-consumer
  config:
    import: optional:configserver:${CONFIG_SERVER_URL:http://localhost:8888}
  docker:
    compose:
      file: ../compose.yaml
  jms:
    pool:
      enabled: true
      max-connections: 20
      max-sessions-per-connection: 10
  kafka:
    bootstrap-servers: localhost:9092
    properties:
      schema.registry.url: http://localhost:8085
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
      acks: 1
      compression-type: lz4
      properties:
        linger.ms: 5
        batch.size: 65536
    consumer:
      group-id: ibm-mq-consumer-group
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
      properties:
        specific.avro.reader: true

app:
  mq:

logging:
  level:
    root: INFO
    com.example.ibmmqconsumer: INFO
    org.springframework: INFO
    org.apache.kafka: WARN
    com.ibm.mq: INFO
    com.ibm.msg: INFO
